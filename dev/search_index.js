var documenterSearchIndex = {"docs":
[{"location":"diffmap/#Diffusion-maps-1","page":"Diffusion maps","title":"Diffusion maps","text":"","category":"section"},{"location":"diffmap/#","page":"Diffusion maps","title":"Diffusion maps","text":"Diffusion maps leverages the relationship between heat diffusion and a random walk; an analogy is drawn between the diffusion operator on a manifold and a Markov transition matrix operating on functions defined on the graph whose nodes were sampled from the manifold [1].","category":"page"},{"location":"diffmap/#","page":"Diffusion maps","title":"Diffusion maps","text":"This package defines a DiffMap type to represent a diffusion map results, and provides a set of methods to access its properties.","category":"page"},{"location":"diffmap/#","page":"Diffusion maps","title":"Diffusion maps","text":"DiffMap\nfit(::Type{DiffMap}, X::AbstractArray{T,2}) where {T<:Real}\ntransform(R::DiffMap)\nManifoldLearning.kernel(R::DiffMap)","category":"page"},{"location":"diffmap/#ManifoldLearning.DiffMap","page":"Diffusion maps","title":"ManifoldLearning.DiffMap","text":"DiffMap{T <: Real} <: AbstractDimensionalityReduction\n\nThe DiffMap type represents diffusion maps model constructed for T type data.\n\n\n\n\n\n","category":"type"},{"location":"diffmap/#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{DiffMap},AbstractArray{T,2}}} where T<:Real","page":"Diffusion maps","title":"StatsAPI.fit","text":"fit(DiffMap, data; maxoutdim=2, t=1, α=1.0, ɛ=1.0)\n\nFit a isometric mapping model to data.\n\nArguments\n\ndata::Matrix: a (nfeatures, nobservations) matrix of observations. Each column of data is an observation. if isnothing(kernel), data is instead the (nobservations, nobservations) precomputed Gram matrix.\n\nKeyword arguments\n\nkernel::Union{Nothing, Function}=(x, y) -> exp(-sum((x .- y) .^ 2) / ɛ): the kernel function. \n\nmaps two input vectors (observations) to a scalar (a metric of their similarity).  by default, a Gaussian kernel. if isnothing(kernel), we assume data is instead   the (nobservations, nobservations) precomputed Gram matrix.\n\nɛ::Real=1.0: the Gaussian kernel variance (the scale parameter). ignored if custom kernel passed.\nmaxoutdim::Int=2: the dimension of the reduced space.\nt::Int=1: the number of transitions\nα::Real=0.0: a normalization parameter\n\nExamples\n\nX = rand(3, 100)     # toy data matrix, 100 observations\n\n# default kernel\nM = fit(DiffMap, X)  # construct diffusion map model\nR = transform(M)     # perform dimensionality reduction\n\n# custom kernel\nkernel = (x, y) -> x' * y # linear kernel\nM = fit(DiffMap, X, kernel=kernel)\n\n# precomputed Gram matrix\nkernel = (x, y) -> x' * y # linear kernel\nK = StatsBase.pairwise(kernel, eachcol(X), symmetric=true) # custom Gram matrix\nM = fit(DiffMap, K, kernel=nothing)\n\n\n\n\n\n","category":"method"},{"location":"diffmap/#MultivariateStats.transform-Tuple{DiffMap}","page":"Diffusion maps","title":"MultivariateStats.transform","text":"transform(R::DiffMap)\n\nTransforms the data fitted to the diffusion map model R into a reduced space representation.\n\n\n\n\n\n","category":"method"},{"location":"diffmap/#ManifoldLearning.kernel-Tuple{DiffMap}","page":"Diffusion maps","title":"ManifoldLearning.kernel","text":"Returns the kernel matrix of the diffusion maps model R\n\n\n\n\n\n","category":"method"},{"location":"diffmap/#References-1","page":"Diffusion maps","title":"References","text":"","category":"section"},{"location":"diffmap/#","page":"Diffusion maps","title":"Diffusion maps","text":"[1]: Coifman, R. & Lafon, S. \"Diffusion maps\". Applied and Computational Harmonic Analysis, Elsevier, 2006, 21, 5-30. DOI:10.1073/pnas.0500334102","category":"page"},{"location":"hlle/#Hessian-Eigenmaps-1","page":"Hessian Eigenmaps","title":"Hessian Eigenmaps","text":"","category":"section"},{"location":"hlle/#","page":"Hessian Eigenmaps","title":"Hessian Eigenmaps","text":"The Hessian Eigenmaps (Hessian LLE, HLLE) method adapts the weights in LLE to minimize the Hessian operator. Like LLE, it requires careful setting of the nearest neighbor parameter. The main advantage of Hessian LLE is the only method designed for non-convex data sets [1].","category":"page"},{"location":"hlle/#","page":"Hessian Eigenmaps","title":"Hessian Eigenmaps","text":"This package defines a HLLE type to represent a Hessian LLE results, and provides a set of methods to access its properties.","category":"page"},{"location":"hlle/#","page":"Hessian Eigenmaps","title":"Hessian Eigenmaps","text":"HLLE\nfit(::Type{HLLE}, X::AbstractArray{T,2}) where {T<:Real}\ntransform(R::HLLE)","category":"page"},{"location":"hlle/#ManifoldLearning.HLLE","page":"Hessian Eigenmaps","title":"ManifoldLearning.HLLE","text":"HLLE{NN <: AbstractNearestNeighbors, T <: Real} <: AbstractDimensionalityReduction\n\nThe HLLE type represents a Hessian eigenmaps model constructed for T type data with a help of the NN nearest neighbor algorithm.\n\n\n\n\n\n","category":"type"},{"location":"hlle/#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{HLLE},AbstractArray{T,2}}} where T<:Real","page":"Hessian Eigenmaps","title":"StatsAPI.fit","text":"fit(HLLE, data; k=12, maxoutdim=2, nntype=BruteForce)\n\nFit a Hessian eigenmaps model to data.\n\nArguments\n\ndata: a matrix of observations. Each column of data is an observation.\n\nKeyword arguments\n\nk: a number of nearest neighbors for construction of local subspace representation\nmaxoutdim: a dimension of the reduced space.\nnntype: a nearest neighbor construction class (derived from AbstractNearestNeighbors)\n\nExamples\n\nM = fit(HLLE, rand(3,100)) # construct Hessian eigenmaps model\nR = transform(M)          # perform dimensionality reduction\n\n\n\n\n\n","category":"method"},{"location":"hlle/#MultivariateStats.transform-Tuple{HLLE}","page":"Hessian Eigenmaps","title":"MultivariateStats.transform","text":"transform(R::LLE)\n\nTransforms the data fitted to the Hessian eigenmaps model R into a reduced space representation.\n\n\n\n\n\n","category":"method"},{"location":"hlle/#References-1","page":"Hessian Eigenmaps","title":"References","text":"","category":"section"},{"location":"hlle/#","page":"Hessian Eigenmaps","title":"Hessian Eigenmaps","text":"[1]: Donoho, D. and Grimes, C. \"Hessian eigenmaps: Locally linear embedding techniques for high-dimensional data\", Proc. Natl. Acad. Sci. USA. 2003 May 13; 100(10): 5591–5596. DOI:10.1073/pnas.1031596100","category":"page"},{"location":"interface/#Programming-interface-1","page":"Interface","title":"Programming interface","text":"","category":"section"},{"location":"interface/#","page":"Interface","title":"Interface","text":"The interface of manifold learning methods in this packages is partially adopted from the packages StatsBase, MultivariateStats.jl and LightGraphs.jl. You can easily implement additional dimensionality reduction algorithms by implementing the following interface.","category":"page"},{"location":"interface/#Types-and-functions-1","page":"Interface","title":"Types and functions","text":"","category":"section"},{"location":"interface/#","page":"Interface","title":"Interface","text":"The following functions are currently available from the interface. AbstractDimensionalityReduction is a an abstract type required for all implemented algorithms models.","category":"page"},{"location":"interface/#","page":"Interface","title":"Interface","text":"AbstractDimensionalityReduction","category":"page"},{"location":"interface/#ManifoldLearning.AbstractDimensionalityReduction","page":"Interface","title":"ManifoldLearning.AbstractDimensionalityReduction","text":"Abstract type for dimensionality reduction methods\n\n\n\n\n\n","category":"type"},{"location":"interface/#","page":"Interface","title":"Interface","text":"For performing the data dimensionality reduction procedure, a model of the data is constructed by calling fit method, and the transformation of the data given the model is done by transform method.","category":"page"},{"location":"interface/#","page":"Interface","title":"Interface","text":"fit(::Type{AbstractDimensionalityReduction}, X::AbstractMatrix)\ntransform(R::AbstractDimensionalityReduction)","category":"page"},{"location":"interface/#StatsAPI.fit-Tuple{Type{AbstractDimensionalityReduction},AbstractArray{T,2} where T}","page":"Interface","title":"StatsAPI.fit","text":"fit(AbstractDimensionalityReduction, X)\n\nPerform model fitting given the data X\n\n\n\n\n\n","category":"method"},{"location":"interface/#MultivariateStats.transform-Tuple{AbstractDimensionalityReduction}","page":"Interface","title":"MultivariateStats.transform","text":"transfrom(R::AbstractDimensionalityReduction)\n\nReturns a reduced space representation of the data given the model R inform of  the projection matrix (of size (d n)), where d is a dimension of the reduced space and n in the number of the observations. Each column of the projection matrix corresponds to an observation in projected reduced space.\n\n\n\n\n\n","category":"method"},{"location":"interface/#","page":"Interface","title":"Interface","text":"There are auxiliary methods that allow to inspect properties of the constructed model.","category":"page"},{"location":"interface/#","page":"Interface","title":"Interface","text":"outdim(R::AbstractDimensionalityReduction)\neigvals(R::AbstractDimensionalityReduction)\nvertices(R::AbstractDimensionalityReduction)\nneighbors(R::AbstractDimensionalityReduction)","category":"page"},{"location":"interface/#MultivariateStats.outdim-Tuple{AbstractDimensionalityReduction}","page":"Interface","title":"MultivariateStats.outdim","text":"outdim(R::AbstractDimensionalityReduction)\n\nReturns a dimension of the reduced space for the model R\n\n\n\n\n\n","category":"method"},{"location":"interface/#LinearAlgebra.eigvals-Tuple{AbstractDimensionalityReduction}","page":"Interface","title":"LinearAlgebra.eigvals","text":"eigvals(R::AbstractDimensionalityReduction)\n\nReturns eignevalues of the reduced space reporesentation for the model R\n\n\n\n\n\n","category":"method"},{"location":"interface/#LightGraphs.vertices-Tuple{AbstractDimensionalityReduction}","page":"Interface","title":"LightGraphs.vertices","text":"vertices(R::AbstractDimensionalityReduction)\n\nReturns vertices of largest connected component in the model R.\n\n\n\n\n\n","category":"method"},{"location":"interface/#LightGraphs.neighbors-Tuple{AbstractDimensionalityReduction}","page":"Interface","title":"LightGraphs.neighbors","text":"neighbors(R::AbstractDimensionalityReduction)\n\nReturns the number of nearest neighbors used for aproximate local subspace\n\n\n\n\n\n","category":"method"},{"location":"isomap/#Isomap-1","page":"Isomap","title":"Isomap","text":"","category":"section"},{"location":"isomap/#","page":"Isomap","title":"Isomap","text":"Isomap is a method for low-dimensional embedding. Isomap is used for computing a quasi-isometric, low-dimensional embedding of a set of high-dimensional data points[1].","category":"page"},{"location":"isomap/#","page":"Isomap","title":"Isomap","text":"This package defines a Isomap type to represent a Isomap calculation results, and provides a set of methods to access its properties.","category":"page"},{"location":"isomap/#","page":"Isomap","title":"Isomap","text":"Isomap\nfit(::Type{Isomap}, X::AbstractArray{T,2}) where {T<:Real}\ntransform(R::Isomap)\ntransform(R::Isomap, X::Union{AbstractArray{T,1}, AbstractArray{T,2}}) where T<:Real","category":"page"},{"location":"isomap/#ManifoldLearning.Isomap","page":"Isomap","title":"ManifoldLearning.Isomap","text":"Isomap{NN <: AbstractNearestNeighbors} <: AbstractDimensionalityReduction\n\nThe Isomap type represents an isometric mapping model constructed with a help of the NN nearest neighbor algorithm.\n\n\n\n\n\n","category":"type"},{"location":"isomap/#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{Isomap},AbstractArray{T,2}}} where T<:Real","page":"Isomap","title":"StatsAPI.fit","text":"fit(Isomap, data; k=12, maxoutdim=2, nntype=BruteForce)\n\nFit an isometric mapping model to data.\n\nArguments\n\ndata: a matrix of observations. Each column of data is an observation.\n\nKeyword arguments\n\nk: a number of nearest neighbors for construction of local subspace representation\nmaxoutdim: a dimension of the reduced space.\nnntype: a nearest neighbor construction class (derived from AbstractNearestNeighbors)\n\nExamples\n\nM = fit(Isomap, rand(3,100)) # construct Isomap model\nR = transform(M)             # perform dimensionality reduction\n\n\n\n\n\n","category":"method"},{"location":"isomap/#MultivariateStats.transform-Tuple{Isomap}","page":"Isomap","title":"MultivariateStats.transform","text":"transform(R::Isomap)\n\nTransforms the data fitted to the Isomap model R into a reduced space representation.\n\n\n\n\n\n","category":"method"},{"location":"isomap/#MultivariateStats.transform-Union{Tuple{T}, Tuple{Isomap,Union{AbstractArray{T,1}, AbstractArray{T,2}}}} where T<:Real","page":"Isomap","title":"MultivariateStats.transform","text":"transform(R::Isomap, X::AbstractVecOrMat)\n\nReturns a transformed out-of-sample data X given the Isomap model R into a reduced space representation.\n\n\n\n\n\n","category":"method"},{"location":"isomap/#References-1","page":"Isomap","title":"References","text":"","category":"section"},{"location":"isomap/#","page":"Isomap","title":"Isomap","text":"[1]: Tenenbaum, J. B., de Silva, V. and Langford, J. C. \"A Global Geometric Framework for Nonlinear Dimensionality Reduction\". Science 290 (5500): 2319-2323, 22 December 2000.","category":"page"},{"location":"lem/#Laplacian-Eigenmaps-1","page":"Laplacian Eigenmaps","title":"Laplacian Eigenmaps","text":"","category":"section"},{"location":"lem/#","page":"Laplacian Eigenmaps","title":"Laplacian Eigenmaps","text":"Laplacian Eigenmaps (LEM) method uses spectral techniques to perform dimensionality reduction. This technique relies on the basic assumption that the data lies in a low-dimensional manifold in a high-dimensional space. The algorithm provides a computationally efficient approach to non-linear dimensionality reduction that has locally preserving properties [1].","category":"page"},{"location":"lem/#","page":"Laplacian Eigenmaps","title":"Laplacian Eigenmaps","text":"This package defines a LEM type to represent a Laplacian eigenmaps results, and provides a set of methods to access its properties.","category":"page"},{"location":"lem/#","page":"Laplacian Eigenmaps","title":"Laplacian Eigenmaps","text":"LEM\nfit(::Type{LEM}, X::AbstractArray{T,2}) where {T<:Real}\ntransform(R::LEM)","category":"page"},{"location":"lem/#ManifoldLearning.LEM","page":"Laplacian Eigenmaps","title":"ManifoldLearning.LEM","text":"LEM{NN <: AbstractNearestNeighbors, T <: Real} <: AbstractDimensionalityReduction\n\nThe LEM type represents a Laplacian eigenmaps model constructed for T type data with a help of the NN nearest neighbor algorithm.\n\n\n\n\n\n","category":"type"},{"location":"lem/#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{LEM},AbstractArray{T,2}}} where T<:Real","page":"Laplacian Eigenmaps","title":"StatsAPI.fit","text":"fit(LEM, data; k=12, maxoutdim=2, ɛ=1.0, nntype=BruteForce)\n\nFit a Laplacian eigenmaps model to data.\n\nArguments\n\ndata: a matrix of observations. Each column of data is an observation.\n\nKeyword arguments\n\nk: a number of nearest neighbors for construction of local subspace representation\nmaxoutdim: a dimension of the reduced space.\nnntype: a nearest neighbor construction class (derived from AbstractNearestNeighbors)\nɛ: a Gaussian kernel variance (the scale parameter)\n\nExamples\n\nM = fit(LEM, rand(3,100)) # construct Laplacian eigenmaps model\nR = transform(M)          # perform dimensionality reduction\n\n\n\n\n\n","category":"method"},{"location":"lem/#MultivariateStats.transform-Tuple{LEM}","page":"Laplacian Eigenmaps","title":"MultivariateStats.transform","text":"transform(R::LEM)\n\nTransforms the data fitted to the Laplacian eigenmaps model R into a reduced space representation.\n\n\n\n\n\n","category":"method"},{"location":"lem/#References-1","page":"Laplacian Eigenmaps","title":"References","text":"","category":"section"},{"location":"lem/#","page":"Laplacian Eigenmaps","title":"Laplacian Eigenmaps","text":"[1]: Belkin, M. and Niyogi, P. \"Laplacian Eigenmaps for Dimensionality Reduction and Data Representation\". Neural Computation, June 2003; 15 (6):1373-1396. DOI:10.1162/089976603321780317","category":"page"},{"location":"ltsa/#Local-Tangent-Space-Alignment-1","page":"Local Tangent Space Alignment","title":"Local Tangent Space Alignment","text":"","category":"section"},{"location":"ltsa/#","page":"Local Tangent Space Alignment","title":"Local Tangent Space Alignment","text":"Local tangent space alignment (LTSA) is a method for manifold learning, which can efficiently learn a nonlinear embedding into low-dimensional coordinates from high-dimensional data, and can also reconstruct high-dimensional coordinates from embedding coordinates [1].","category":"page"},{"location":"ltsa/#","page":"Local Tangent Space Alignment","title":"Local Tangent Space Alignment","text":"This package defines a LTSA type to represent a local tangent space alignment results, and provides a set of methods to access its properties.","category":"page"},{"location":"ltsa/#","page":"Local Tangent Space Alignment","title":"Local Tangent Space Alignment","text":"LTSA\nfit(::Type{LTSA}, X::AbstractArray{T,2}) where {T<:Real}\ntransform(R::LTSA)","category":"page"},{"location":"ltsa/#ManifoldLearning.LTSA","page":"Local Tangent Space Alignment","title":"ManifoldLearning.LTSA","text":"LTSA{NN <: AbstractNearestNeighbors, T <: Real} <: AbstractDimensionalityReduction\n\nThe LTSA type represents a local tangent space alignment model constructed for T type data with a help of the NN nearest neighbor algorithm.\n\n\n\n\n\n","category":"type"},{"location":"ltsa/#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{LTSA},AbstractArray{T,2}}} where T<:Real","page":"Local Tangent Space Alignment","title":"StatsAPI.fit","text":"fit(LTSA, data; k=12, maxoutdim=2, nntype=BruteForce)\n\nFit a local tangent space alignment model to data.\n\nArguments\n\ndata: a matrix of observations. Each column of data is an observation.\n\nKeyword arguments\n\nk: a number of nearest neighbors for construction of local subspace representation\nmaxoutdim: a dimension of the reduced space.\nnntype: a nearest neighbor construction class (derived from AbstractNearestNeighbors)\n\nExamples\n\nM = fit(LTSA, rand(3,100)) # construct LTSA model\nR = transform(M)           # perform dimensionality reduction\n\n\n\n\n\n","category":"method"},{"location":"ltsa/#MultivariateStats.transform-Tuple{LTSA}","page":"Local Tangent Space Alignment","title":"MultivariateStats.transform","text":"transform(R::LTSA)\n\nTransforms the data fitted to the local tangent space alignment model R into a reduced space representation.\n\n\n\n\n\n","category":"method"},{"location":"ltsa/#References-1","page":"Local Tangent Space Alignment","title":"References","text":"","category":"section"},{"location":"ltsa/#","page":"Local Tangent Space Alignment","title":"Local Tangent Space Alignment","text":"[1]: Zhang, Zhenyue; Hongyuan Zha. \"Principal Manifolds and Nonlinear Dimension Reduction via Local Tangent Space Alignment\". SIAM Journal on Scientific Computing 26 (1): 313–338, 2004. DOI:10.1137/s1064827502419154","category":"page"},{"location":"#ManifoldLearning.jl-1","page":"Home","title":"ManifoldLearning.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The package ManifoldLearning aims to provide a library for manifold learning and non-linear dimensionality reduction. It provides set of nonlinear dimensionality reduction methods, such as Isomap, LLE, LTSA, and etc.","category":"page"},{"location":"#Getting-started-1","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"To install the package just type","category":"page"},{"location":"#","page":"Home","title":"Home","text":"] add ManifoldLearning","category":"page"},{"location":"#","page":"Home","title":"Home","text":"A simple example of using the Isomap dimensionality reduction method on the build-in Swiss roll dataset, ManifoldLearning.swiss_roll.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"using ManifoldLearning\nX, _ = ManifoldLearning.swiss_roll();\nX\nM = fit(Isomap, X)\nY = transform(M)","category":"page"},{"location":"#Methods-1","page":"Home","title":"Methods","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Methods Description\nIsomap Isometric mapping\nLLE Locally Linear Embedding\nHLLE Hessian Eigenmaps\nLEM Laplacian Eigenmaps\nLTSA Local Tangent Space Alignment\nDiffMap Diffusion maps","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Notes: All methods implemented in this package adopt the column-major convention of JuliaStats: in a data matrix, each column corresponds to a sample/observation, while each row corresponds to a feature (variable or attribute).","category":"page"},{"location":"lle/#Locally-Linear-Embedding-1","page":"Locally Linear Embedding","title":"Locally Linear Embedding","text":"","category":"section"},{"location":"lle/#","page":"Locally Linear Embedding","title":"Locally Linear Embedding","text":"Locally Linear Embedding (LLE) technique builds a single global coordinate system of lower dimensionality. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds [1].","category":"page"},{"location":"lle/#","page":"Locally Linear Embedding","title":"Locally Linear Embedding","text":"This package defines a LLE type to represent a LLE results, and provides a set of methods to access its properties.","category":"page"},{"location":"lle/#","page":"Locally Linear Embedding","title":"Locally Linear Embedding","text":"LLE\nfit(::Type{LLE}, X::AbstractArray{T,2}) where {T<:Real}\ntransform(R::LLE)","category":"page"},{"location":"lle/#ManifoldLearning.LLE","page":"Locally Linear Embedding","title":"ManifoldLearning.LLE","text":"LLE{NN <: AbstractNearestNeighbors, T <: Real} <: AbstractDimensionalityReduction\n\nThe LLE type represents a locally linear embedding model constructed for T type data constructed with a help of the NN nearest neighbor algorithm.\n\n\n\n\n\n","category":"type"},{"location":"lle/#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{LLE},AbstractArray{T,2}}} where T<:Real","page":"Locally Linear Embedding","title":"StatsAPI.fit","text":"fit(LLE, data; k=12, maxoutdim=2, nntype=BruteForce, tol=1e-5)\n\nFit a locally linear embedding model to data.\n\nArguments\n\ndata: a matrix of observations. Each column of data is an observation.\n\nKeyword arguments\n\nk: a number of nearest neighbors for construction of local subspace representation\nmaxoutdim: a dimension of the reduced space.\nnntype: a nearest neighbor construction class (derived from AbstractNearestNeighbors)\ntol: an algorithm regularization tolerance\n\nExamples\n\nM = fit(LLE, rand(3,100)) # construct LLE model\nR = transform(M)          # perform dimensionality reduction\n\n\n\n\n\n","category":"method"},{"location":"lle/#MultivariateStats.transform-Tuple{LLE}","page":"Locally Linear Embedding","title":"MultivariateStats.transform","text":"transform(R::LLE)\n\nTransforms the data fitted to the LLE model R into a reduced space representation.\n\n\n\n\n\n","category":"method"},{"location":"lle/#References-1","page":"Locally Linear Embedding","title":"References","text":"","category":"section"},{"location":"lle/#","page":"Locally Linear Embedding","title":"Locally Linear Embedding","text":"[1]: Roweis, S. & Saul, L. \"Nonlinear dimensionality reduction by locally linear embedding\", Science 290:2323 (2000). DOI:10.1126/science.290.5500.2323","category":"page"},{"location":"datasets/#Datasets-1","page":"Datasets","title":"Datasets","text":"","category":"section"},{"location":"datasets/#","page":"Datasets","title":"Datasets","text":"The ManifoldLearning package provides an implementation of the swiss roll and the spirals datasets.","category":"page"},{"location":"datasets/#","page":"Datasets","title":"Datasets","text":"(Image: )","category":"page"},{"location":"datasets/#","page":"Datasets","title":"Datasets","text":"ManifoldLearning.swiss_roll","category":"page"},{"location":"datasets/#ManifoldLearning.swiss_roll","page":"Datasets","title":"ManifoldLearning.swiss_roll","text":"swiss_roll(n::Int, noise::Float64)\n\nGenerate a swiss roll dataset of n points with point coordinate noise variance.\n\n\n\n\n\n","category":"function"},{"location":"datasets/#","page":"Datasets","title":"Datasets","text":"(Image: )","category":"page"},{"location":"datasets/#","page":"Datasets","title":"Datasets","text":"ManifoldLearning.spirals","category":"page"},{"location":"datasets/#ManifoldLearning.spirals","page":"Datasets","title":"ManifoldLearning.spirals","text":"spirals(n::Int, noise::Float64)\n\nGenerate a spirals dataset of n points with point coordinate noise variance.\n\n\n\n\n\n","category":"function"}]
}
